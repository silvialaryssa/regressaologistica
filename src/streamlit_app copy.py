import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from scipy.stats import shapiro
from statsmodels.stats.diagnostic import het_breuschpagan
from statsmodels.stats.outliers_influence import variance_inflation_factor

st.set_page_config(page_title="An√°lise de Churn", layout="wide")

# Carregamento dos dados
@st.cache_data
def load_data():
    df = pd.read_csv("src/Churn_Modelling.csv")
    df.rename(columns={'Exited': 'Churn'}, inplace=True)
    return df

df = load_data()

# Sidebar
st.sidebar.title("üîß Navega√ß√£o")
show_dados = st.sidebar.checkbox("Exibir dados", value=False)
show_eda = st.sidebar.checkbox("Exibir An√°lise Explorat√≥ria", value=False)
show_model = st.sidebar.checkbox("Exibir Modelagem com Regress√£o Log√≠stica", value=False)

st.title("üîç Painel de Churn ‚Äì Reten√ß√£o de Clientes do Banco")



def avaliar_violacoes_e_sugestoes(shapiro_p, bp_pvalue, vif_table, figs_linearidade=None):
    """
    Avalia viola√ß√µes de pressupostos e sugere alternativas.
    Par√¢metros:
        - shapiro_p: p-valor do teste de Shapiro-Wilk (normalidade dos res√≠duos)
        - bp_pvalue: p-valor do teste de Breusch-Pagan (homocedasticidade)
        - vif_table: DataFrame com VIFs das vari√°veis
        - figs_linearidade: Lista de gr√°ficos de res√≠duos vs preditores
    Retorna:
        Texto com interpreta√ß√µes e sugest√µes.
    """
    sugestoes = []

    # 1. Normalidade dos res√≠duos
    if shapiro_p < 0.05:
        sugestoes.append("‚ùå **Normalidade dos res√≠duos violada** (p-valor do Shapiro-Wilk < 0.05).\
        \n‚û°Ô∏è Sugest√£o: Aplicar transforma√ß√µes (ex: log, Box-Cox) ou utilizar **Regress√£o Quant√≠lica**.")

    # 2. Homocedasticidade
    if bp_pvalue < 0.05:
        sugestoes.append("‚ùå **Heterocedasticidade detectada** (p-valor do teste de Breusch-Pagan < 0.05).\
        \n‚û°Ô∏è Sugest√£o: Utilizar **Regress√£o Robusta** (ex: `HuberRegressor`, `RLM` do `statsmodels`).")

    # 3. Multicolinearidade
    variaveis_com_vif_alto = vif_table[vif_table["VIF"] > 5]["Vari√°vel"].tolist()
    if len(variaveis_com_vif_alto) > 0:
        sugestoes.append(f"‚ùå **Multicolinearidade identificada nas vari√°veis:** {', '.join(variaveis_com_vif_alto)}.\
        \n‚û°Ô∏è Sugest√£o: Utilizar **modelos com regulariza√ß√£o** como **Ridge**, **Lasso** ou **ElasticNet**.")

    # 4. Linearidade (avalia√ß√£o visual)
    if figs_linearidade:
        sugestoes.append("‚ö†Ô∏è **Verifique os gr√°ficos de res√≠duos vs preditores.**\
        \nSe houver padr√µes n√£o aleat√≥rios, pode haver viola√ß√£o da suposi√ß√£o de **linearidade**.\
        \n‚û°Ô∏è Sugest√£o: Utilizar **Regress√£o Polinomial** ou **modelos baseados em √°rvore** (ex: `Random Forest`).")

    if not sugestoes:
        return "‚úÖ Todos os pressupostos parecem estar atendidos. O modelo de Regress√£o Log√≠stica √© apropriado."

    return "\n\n".join(sugestoes)




# -----------------------------
# Fun√ß√£o de valida√ß√£o de pressupostos
# -----------------------------


def validar_pressupostos_completo(X, y, modelo_pipeline):
    """
    Valida pressupostos da regress√£o log√≠stica:
        1. Normalidade dos res√≠duos (Q-Q plot + Shapiro-Wilk)
        2. Homocedasticidade (res√≠duos vs valores previstos + Breusch-Pagan)
        3. Multicolinearidade (VIF)
        4. Linearidade (res√≠duos vs cada preditor j√° transformado)

    Par√¢metros
    ----------
    X : pd.DataFrame ou np.ndarray
        Dados de teste (features) antes da transforma√ß√£o do pipeline.
    y : pd.Series ou np.ndarray
        Valores reais (target) correspondentes a X.
    modelo_pipeline : sklearn.pipeline.Pipeline
        Pipeline j√° treinado contendo:
            - step 'prep' : transformador (por ex. ColumnTransformer)
            - step 'logreg' : modelo LogisticRegression

    Retorno
    -------
    dict com:
        - fig_qqplot                : Matplotlib Figure
        - shapiro_p                 : float
        - fig_homocedasticidade     : Matplotlib Figure
        - bp_pvalue                 : float
        - vif_table                 : pd.DataFrame
        - figs_linearidade          : list[Matplotlib Figure]
    """

    # ----- 0. Prepara√ß√£o -----
    # X transformado pelo pr√©-processador
    X_transf = modelo_pipeline.named_steps['prep'].transform(X)
    # Probabilidade prevista (classe positiva)
    y_pred_prob = modelo_pipeline.named_steps['logreg'].predict_proba(X_transf)[:, 1]
    # Res√≠duos (observado ‚àí previsto)
    residuos = y - y_pred_prob

    # ----- 1. Normalidade dos res√≠duos -----
    fig_qqplot, ax_qq = plt.subplots()
    sm.qqplot(residuos, line='45', ax=ax_qq)
    ax_qq.set_title('Q-Q Plot dos Res√≠duos')

    # Teste de Shapiro-Wilk
    shapiro_stat, shapiro_p = shapiro(residuos)

    # ----- 2. Homocedasticidade -----
    fig_homo, ax_homo = plt.subplots()
    ax_homo.scatter(y_pred_prob, residuos, alpha=0.5)
    ax_homo.axhline(y=0, color='r', linestyle='--')
    ax_homo.set_xlabel("Valores previstos (probabilidades)")
    ax_homo.set_ylabel("Res√≠duos")
    ax_homo.set_title("Res√≠duos vs Valores Previstos")

    # Breusch-Pagan
    # Precisa de matriz explicativa com intercepto
    exog_bp = sm.add_constant(X_transf, prepend=False)
    _, bp_pvalue, _, _ = het_breuschpagan(residuos, exog_bp)

    # ----- 3. Multicolinearidade (VIF) -----
    feature_names = modelo_pipeline.named_steps['prep'].get_feature_names_out()
    vif_data = pd.DataFrame({
        "Vari√°vel": feature_names,
        "VIF": [variance_inflation_factor(X_transf, i)
                for i in range(X_transf.shape[1])]
    }).round(2)

    # ----- 4. Linearidade (res√≠duos vs preditores) -----
    figs_linearidade = []
    for idx, fname in enumerate(feature_names):
        fig_lin, ax_lin = plt.subplots()
        ax_lin.scatter(X_transf[:, idx], residuos, alpha=0.5)
        ax_lin.axhline(y=0, color='r', linestyle='--')
        ax_lin.set_title(f"Res√≠duos vs {fname}")
        ax_lin.set_xlabel(fname)
        ax_lin.set_ylabel("Res√≠duos")
        figs_linearidade.append(fig_lin)

    # ----- 5. Retorno -----
    resultados = {
        "fig_qqplot": fig_qqplot,
        "shapiro_p": shapiro_p,
        "fig_homocedasticidade": fig_homo,
        "bp_pvalue": bp_pvalue,
        "vif_table": vif_data,
        "figs_linearidade": figs_linearidade
    }

    return resultados




# ------------------------------
# VISUALIZA√á√ÉO GERAL DOS DADOS
# ------------------------------
if show_dados:
    st.header("üìä Visualiza√ß√£o dos Dados Gerais")
    st.dataframe(df.head(10), use_container_width=True)
    st.markdown("---")
    st.caption("Desenvolvido por Silvia Laryssa ‚Äì Streamlit + Plotly üìä")

# ------------------------------
# AN√ÅLISE EXPLORAT√ìRIA
# ------------------------------
if show_eda:
    st.header("üìà An√°lise Explorat√≥ria de Churn")

    # Distribui√ß√£o
    st.subheader("Distribui√ß√£o da vari√°vel alvo (Churn)")
    fig_churn = px.histogram(df, x='Churn', color='Churn',
                             category_orders={'Churn': [0, 1]},
                             labels={'Churn': 'Cliente saiu'},
                             title='Distribui√ß√£o de Clientes que Sa√≠ram (Churn)')
    st.plotly_chart(fig_churn, use_container_width=True)

    # Num√©ricas
    st.subheader("üìä Vari√°veis Num√©ricas vs Churn")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.plotly_chart(px.box(df, x='Churn', y='Age', color='Churn', title='Idade vs Churn'), use_container_width=True)
        st.plotly_chart(px.box(df, x='Churn', y='CreditScore', color='Churn', title='Score de Cr√©dito vs Churn'), use_container_width=True)

    with col2:
        st.plotly_chart(px.box(df, x='Churn', y='Balance', color='Churn', title='Saldo vs Churn'), use_container_width=True)
        st.plotly_chart(px.box(df, x='Churn', y='EstimatedSalary', color='Churn', title='Sal√°rio Estimado vs Churn'), use_container_width=True)

    with col3:
        st.plotly_chart(px.box(df, x='Churn', y='Tenure', color='Churn', title='Tempo de Perman√™ncia vs Churn'), use_container_width=True)
        st.plotly_chart(px.box(df, x='Churn', y='NumOfProducts', color='Churn', title='N√∫mero de Produtos vs Churn'), use_container_width=True)

    # Categ√≥ricas
    st.subheader("üì¶ Vari√°veis Categ√≥ricas vs Churn")
    col4, col5, col6, col7 = st.columns(4)

    with col4:
        st.plotly_chart(px.histogram(df, x='NumOfProducts', color='Churn', barmode='group',
                                     title='N√∫mero de Produtos vs Churn'), use_container_width=True)

    with col5:
        st.plotly_chart(px.histogram(df, x='IsActiveMember', color='Churn', barmode='group',
                                     title='Cliente Ativo vs Churn',
                                     labels={'IsActiveMember': 'Ativo (1=Sim, 0=N√£o)'}), use_container_width=True)

    with col6:
        st.plotly_chart(px.histogram(df, x='Geography', color='Churn', barmode='group',
                                     title='Geografia vs Churn'), use_container_width=True)

    with col7:
        st.plotly_chart(px.histogram(df, x='Gender', color='Churn', barmode='group',
                                     title='G√™nero vs Churn'), use_container_width=True)

    st.markdown("---")
    st.caption("Desenvolvido por Silvia Laryssa ‚Äì Streamlit + Plotly üìä")

# ------------------------------
# MODELAGEM COM REGRESS√ÉO LOG√çSTICA
# ------------------------------
if show_model:
    st.header("üß† Quest√£o A e C - Modelagem com Regress√£o Log√≠stica (Reten√ß√£o de Clientes)")

    st.markdown("Selecionando vari√°veis explicativas mais relevantes:")
    st.code("Age, Balance, IsActiveMember, NumOfProducts, Geography")

    X = df[['Age', 'Balance', 'IsActiveMember', 'NumOfProducts', 'Geography']]
    y = df['Churn']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    preprocessor = ColumnTransformer(
        transformers=[('geo', OneHotEncoder(drop='first'), ['Geography'])],
        remainder='passthrough'
    )

    pipeline = Pipeline([
        ('prep', preprocessor),
        ('logreg', LogisticRegression(max_iter=1000))
    ])

    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    st.subheader("üìã Avalia√ß√£o do Modelo")
    cm = confusion_matrix(y_test, y_pred)
    st.write("**Matriz de Confus√£o:**")
    st.dataframe(pd.DataFrame(cm, columns=["Previsto 0", "Previsto 1"], index=["Real 0", "Real 1"]))

    st.markdown("**Relat√≥rio de Classifica√ß√£o:**")
    report = classification_report(y_test, y_pred, output_dict=True)
    st.dataframe(pd.DataFrame(report).transpose().round(2))

    st.subheader("üìà Coeficientes do Modelo")

    feature_names = pipeline.named_steps['prep'].get_feature_names_out()
    coef = pipeline.named_steps['logreg'].coef_[0]
    odds = np.exp(coef)

    coef_table = pd.DataFrame({
        'Vari√°vel': feature_names,
        'Coeficiente': coef.round(3),
        'Odds Ratio': odds.round(3)
    }).sort_values(by='Coeficiente', ascending=False)

    st.dataframe(coef_table)

    # ------------------------------
    # VALIDA√á√ÉO DOS PRESSUPOSTOS
    # ------------------------------
    st.header("üîé Valida√ß√£o dos Pressupostos da Regress√£o Log√≠stica")

    resultados = validar_pressupostos_completo(X_test, y_test, pipeline)

    # 1. Normalidade dos Res√≠duos
    st.subheader("1. Normalidade dos Res√≠duos")
    st.pyplot(resultados["fig_qqplot"])
    st.markdown(f"**Teste de Shapiro-Wilk ‚Äì p-valor:** `{resultados['shapiro_p']:.4f}`")
    if resultados["shapiro_p"] < 0.05:
        st.warning("A normalidade dos res√≠duos foi violada (p < 0.05).")

    # 2. Homocedasticidade
    st.subheader("2. Homocedasticidade")
    st.pyplot(resultados["fig_homocedasticidade"])
    st.markdown(f"**Teste de Breusch-Pagan ‚Äì p-valor:** `{resultados['bp_pvalue']:.4f}`")
    if resultados["bp_pvalue"] < 0.05:
        st.warning("Heterocedasticidade detectada (p < 0.05).")

    # 3. Multicolinearidade (VIF)
    st.subheader("3. Multicolinearidade (VIF)")
    st.dataframe(resultados["vif_table"])
    if resultados["vif_table"]["VIF"].max() > 5:
        st.warning("Algumas vari√°veis apresentam VIF > 5, indicando multicolinearidade.")

    # 4. Linearidade
    st.subheader("4. Linearidade ‚Äì Res√≠duos vs Preditores")
    st.markdown("Verifique visualmente se h√° padr√µes sistem√°ticos. Idealmente, os pontos devem estar distribu√≠dos aleatoriamente.")
    for fig in resultados["figs_linearidade"]:
        st.pyplot(fig)

    # 5. Sugest√µes baseadas nas viola√ß√µes
    st.subheader("üß™ Diagn√≥stico e Sugest√µes com base nas Viola√ß√µes")
    sugestoes_texto = avaliar_violacoes_e_sugestoes(
        shapiro_p=resultados["shapiro_p"],
        bp_pvalue=resultados["bp_pvalue"],
        vif_table=resultados["vif_table"],
        figs_linearidade=resultados["figs_linearidade"]
    )
    st.markdown(sugestoes_texto)


    
    # dataframe com a interpreta√ß√£o dos coeficientes
    st.header("üìä Tabela Interpretativa dos Coeficientes")

    # Dados da tabela interpretativa
    data_interpretativa = {
        "Vari√°vel": [
            "geo__Geography_Germany",
            "geo__Geography_Spain",
            "remainder__Age",
            "remainder__Balance",
            "remainder__NumOfProducts",
            "remainder__IsActiveMember"
        ],
        "Coeficiente": [
            "+0.798",
            "+0.084",
            "+0.072",
            "0",
            "‚Äì0.075",
            "‚Äì1.059"
        ],
        "Odds Ratio": [
            "2.222",
            "1.088",
            "1.075",
            "1.000",
            "0.928",
            "0.347"
        ],
        "Impacto sobre o Churn (%)": [
            "+122,2%",
            "+8,8%",
            "+7,5% por ano",
            "0%",
            "‚Äì7,2% por produto",
            "‚Äì65,3%"
        ],
        "Interpreta√ß√£o Detalhada": [
            "Clientes da Alemanha t√™m 2,2x mais chance de churn do que clientes da Fran√ßa (grupo base). Forte associa√ß√£o com sa√≠da.",
            "Clientes da Espanha t√™m 8,8% mais chance de churn comparado √† Fran√ßa. Efeito pequeno, quase neutro.",
            "A cada ano a mais de idade, a chance de churn aumenta em 7,5%, sugerindo maior sa√≠da entre clientes mais velhos.",
            "O saldo na conta n√£o teve efeito significativo sobre o churn neste modelo.",
            "Cada produto banc√°rio adicional reduz a chance de churn em 7,2%. Clientes com mais produtos s√£o mais fi√©is.",
            "Clientes ativos t√™m 65,3% menos chance de churn. √â o fator mais forte de reten√ß√£o no modelo."
        ]
    }

    st.markdown("### üß© Conclus√µes Estrat√©gicas da An√°lise de Churn")

    st.markdown("""
    - **Clientes ativos** t√™m muito menos chance de churn. √â essencial investir em estrat√©gias para engajar clientes inativos (como campanhas de reativa√ß√£o e uso do app).
    - **Mais produtos banc√°rios** reduzem o churn, sugerindo que a√ß√µes de venda cruzada (cross-selling) aumentam a fideliza√ß√£o.
    - **Clientes da Alemanha** apresentam maior risco de sa√≠da, exigindo interven√ß√µes regionais e an√°lise de causas locais (como concorr√™ncia e oferta de servi√ßos).
    - **A idade** est√° positivamente associada ao churn. √â necess√°rio adaptar servi√ßos e comunica√ß√£o para faixas et√°rias mais velhas.
    - **Saldo banc√°rio** n√£o influencia significativamente o churn, indicando que a reten√ß√£o depende mais do relacionamento do que do volume financeiro.
    - Esses achados apoiam **campanhas personalizadas**, **melhorias espec√≠ficas por regi√£o** e **ajustes no portf√≥lio de produtos**.
    - O modelo permite tomadas de decis√£o mais **assertivas e direcionadas**, contribuindo fortemente para a **estrat√©gia de reten√ß√£o**.
    """)


    df_interpretativa = pd.DataFrame(data_interpretativa)

    # Exibir a tabela no Streamlit
    st.table(df_interpretativa)

    st.markdown("---")
    st.caption("üîç Coeficientes positivos aumentam a chance de churn; negativos indicam maior reten√ß√£o.")

    
   

    st.markdown("> **Interpreta√ß√£o:** Coeficientes positivos aumentam a chance de churn; negativos diminuem. A coluna `Odds Ratio` mostra quanto a chance √© multiplicada para cada unidade da vari√°vel.")
