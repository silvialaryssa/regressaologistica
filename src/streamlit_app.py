import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from scipy.stats import shapiro
from statsmodels.stats.diagnostic import het_breuschpagan
from statsmodels.stats.outliers_influence import variance_inflation_factor
import altair as alt

st.set_page_config(page_title="An√°lise de Churn", layout="wide")

# Carregamento dos dados
@st.cache_data
def load_data():
    df = pd.read_csv("src/Churn_Modelling.csv")
    df.rename(columns={'Exited': 'Churn'}, inplace=True)
    return df

df = load_data()

# Sidebar
st.sidebar.title("üîß Navega√ß√£o")
show_dados = st.sidebar.checkbox("Exibir dados", value=False)
show_eda = st.sidebar.checkbox("Exibir An√°lise Explorat√≥ria", value=False)
show_model = st.sidebar.checkbox("Exibir Modelagem com Regress√£o Log√≠stica", value=False)

# Observa√ß√£o extra sobre SMOTE
st.sidebar.markdown("---")
st.sidebar.markdown("üìå **Observa√ß√£o:**")
st.sidebar.info("Na etapa **Diagn√≥stico Final**, voc√™ poder√° escolher se deseja aplicar SMOTE para balancear as classes. Essa op√ß√£o ser√° exibida somente ao ativar a modelagem.")


st.title("üîç Painel de Churn ‚Äì Reten√ß√£o de Clientes do Banco")


# -----------------------------
# Fun√ß√£o de valida√ß√£o de pressupostos
# -----------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
from imblearn.over_sampling import SMOTE

def validar_pressupostos_logistica(X, y, model_pipeline):
    resultados = {}

    # 1. Balanceamento da vari√°vel dependente
    churn_counts = y.value_counts(normalize=True)
    resultados['balanceamento'] = churn_counts.to_dict()

    # 2. Verificar Multicolinearidade com VIF
    X_encoded = pd.get_dummies(X, drop_first=True)
    X_scaled = StandardScaler().fit_transform(X_encoded)
    vif_data = pd.DataFrame()
    vif_data["Vari√°vel"] = X_encoded.columns
    vif_data["VIF"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]
    resultados['vif_table'] = vif_data

    #3. Linearidade do logit (Box-Tidwell simplificado)
    # Ajustar modelo log√≠stico usando statsmodels
        # Codificar vari√°vel categ√≥rica
    preprocessor = ColumnTransformer(
        transformers=[('geo', OneHotEncoder(drop='first'), ['Geography'])],
        remainder='passthrough'
    )

    X_encoded = preprocessor.fit_transform(X)
    feature_names = preprocessor.get_feature_names_out()
    X_encoded_df = pd.DataFrame(X_encoded, columns=feature_names)

    # Adicionar constante e ajustar modelo log√≠stico
    X_logit = sm.add_constant(X_encoded_df).reset_index(drop=True)
    y_alinhado = y.reset_index(drop=True)
    logit_model = sm.Logit(y_alinhado, X_logit)
    result = logit_model.fit()

    # Obter res√≠duos e valores ajustados
    residuos = result.resid_pearson
    fitted = result.fittedvalues

    # Gr√°fico: res√≠duos vs valores ajustados
   # Criar DataFrame com res√≠duos e valores ajustados
    df_residuos = pd.DataFrame({
        'Valores Ajustados': fitted,
        'Res√≠duos': residuos
    })

    # Gr√°fico interativo com Altair
    fig_linearidade = alt.Chart(df_residuos).mark_circle(size=60, opacity=0.5).encode(
        x=alt.X('Valores Ajustados', title='Valores Ajustados'),
        y=alt.Y('Res√≠duos', title='Res√≠duos'),
        tooltip=['Valores Ajustados', 'Res√≠duos']
    ).properties(
        title='Res√≠duos Pearson vs Logit Ajustado',
        width=600,
        height=400
    ).interactive()
      # linha de suaviza√ß√£o (LOWESS)
    linha = fig_linearidade.transform_loess('Valores Ajustados', 'Res√≠duos').mark_line(color='red')
    fig_linearidade = fig_linearidade + linha

    resultados['fig_linearidade'] = fig_linearidade

    # 4. Verificar necessidade de SMOTE
    resultados['aplicar_smote'] = True if churn_counts.min() < 0.3 else False

    # 5. Verificar necessidade de regulariza√ß√£o
    resultados['recomendar_regularizacao'] = True if vif_data['VIF'].max() > 5 else False

    return resultados


# ------------------------------
# diagn√≥stico de agrupamento

import pandas as pd
import numpy as np
import altair as alt

def diagnostico_agrupamentos(pipeline, X_test, y_test):
    # Pega os nomes das vari√°veis ap√≥s transforma√ß√£o
    feature_names = pipeline.named_steps['prep'].get_feature_names_out()

    # Obt√©m X_test processado (OneHot + num√©ricas)
    X_encoded = pipeline.named_steps['prep'].transform(X_test)
    X_encoded_df = pd.DataFrame(X_encoded, columns=feature_names).reset_index(drop=True)
    y_aligned = y_test.reset_index(drop=True)

    # Ajusta modelo com statsmodels (para obter logit e res√≠duos)
    import statsmodels.api as sm
    X_logit = sm.add_constant(X_encoded_df)
    logit_model = sm.Logit(y_aligned, X_logit).fit(disp=0)
    residuos = logit_model.resid_pearson
    fitted = logit_model.fittedvalues

    # Adiciona ao DataFrame
    X_encoded_df["logit"] = fitted
    X_encoded_df["residuos"] = residuos

    st.subheader("üîé An√°lise de Agrupamentos por Vari√°vel Categ√≥rica")
    for col in X_encoded_df.columns:
        if col in ["logit", "residuos"]:
            continue
        if set(X_encoded_df[col].unique()) == {0, 1}:
            chart = alt.Chart(X_encoded_df).mark_circle(size=60, opacity=0.5).encode(
                x='logit',
                y='residuos',
                color=alt.Color(col, legend=alt.Legend(title=col)),
                tooltip=[col, 'logit', 'residuos']
            ).properties(
                width=600,
                height=300,
                title=f"Res√≠duos vs Logit (Agrupado por: {col})"
            )
            st.altair_chart(chart)

    st.subheader("üìà Linearidade dos Preditores Num√©ricos")
    variaveis_numericas = ['remainder__Age', 'remainder__Balance', 'remainder__NumOfProducts']

    for col in variaveis_numericas:
        scatter = alt.Chart(X_encoded_df).mark_circle(size=60, opacity=0.5).encode(
            x=alt.X(col, title=col.split("__")[-1]),
            y=alt.Y('residuos', title='Res√≠duos'),
            tooltip=['logit', col]
        ).properties(
            width=600,
            height=300,
            title=f"Res√≠duos vs {col.split('__')[-1]}"
        )

        linha = scatter.transform_loess(col, 'residuos').mark_line(color='red')

        st.altair_chart(scatter + linha)

    # Pega os nomes das vari√°veis ap√≥s transforma√ß√£o
    feature_names = pipeline.named_steps['prep'].get_feature_names_out()

    # Obt√©m X_test processado (OneHot + num√©ricas)
    X_encoded = pipeline.named_steps['prep'].transform(X_test)
    X_encoded_df = pd.DataFrame(X_encoded, columns=feature_names).reset_index(drop=True)
    y_aligned = y_test.reset_index(drop=True)

    ## Ajusta modelo com statsmodels (para obter logit e res√≠duos)
    #import statsmodels.api as sm
    #X_logit = sm.add_constant(X_encoded_df)
    #logit_model = sm.Logit(y_aligned, X_logit).fit(disp=0)
    #residuos = logit_model.resid_pearson
    #fitted = logit_model.fittedvalues

    # Adiciona ao DataFrame
    #X_encoded_df["logit"] = fitted
    #X_encoded_df["residuos"] = residuos

   # st.subheader("üîé An√°lise de Agrupamentos por Vari√°vel")

    #for col in X_encoded_df.columns:
     #   if col in ["logit", "residuos"]:
      #      continue  # pula vari√°veis j√° usadas no gr√°fico
        # Verifica se √© dummy
       ## if set(X_encoded_df[col].unique()) == {0, 1}:
         #   chart = alt.Chart(X_encoded_df).mark_circle(size=60, opacity=0.5).encode(
          #      x='logit',
          #      y='residuos',
          #      color=alt.Color(col, legend=alt.Legend(title=col)),
          #      tooltip=[col, 'logit', 'residuos']
          #  ).properties(
          #      width=600,
          #      height=300,
          #      title=f"Res√≠duos vs Logit colorido por: {col}"
           # )
           # st.altair_chart(chart)





# ------------------------------
# VISUALIZA√á√ÉO GERAL DOS DADOS
# ------------------------------
if show_dados:
    st.header("üìä Visualiza√ß√£o dos Dados Gerais")
    st.dataframe(df.head(10), use_container_width=True)
    st.markdown("---")

# ------------------------------
# AN√ÅLISE EXPLORAT√ìRIA
# ------------------------------
if show_eda:
    st.header("üìà An√°lise Explorat√≥ria de Churn")

    # Distribui√ß√£o
    st.subheader("Distribui√ß√£o da vari√°vel alvo (Churn)")
    fig_churn = px.histogram(df, x='Churn', color='Churn',
                             category_orders={'Churn': [0, 1]},
                             labels={'Churn': 'Cliente saiu'},
                             title='Distribui√ß√£o de Clientes que Sa√≠ram (Churn)')
    st.plotly_chart(fig_churn, use_container_width=True)

    # Num√©ricas
    st.subheader("üìä Vari√°veis Num√©ricas vs Churn")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.plotly_chart(px.box(df, x='Churn', y='Age', color='Churn', title='Idade vs Churn'), use_container_width=True)
        st.plotly_chart(px.box(df, x='Churn', y='CreditScore', color='Churn', title='Score de Cr√©dito vs Churn'), use_container_width=True)

    with col2:
        st.plotly_chart(px.box(df, x='Churn', y='Balance', color='Churn', title='Saldo vs Churn'), use_container_width=True)
        st.plotly_chart(px.box(df, x='Churn', y='EstimatedSalary', color='Churn', title='Sal√°rio Estimado vs Churn'), use_container_width=True)

    with col3:
        st.plotly_chart(px.box(df, x='Churn', y='Tenure', color='Churn', title='Tempo de Perman√™ncia vs Churn'), use_container_width=True)
        st.plotly_chart(px.box(df, x='Churn', y='NumOfProducts', color='Churn', title='N√∫mero de Produtos vs Churn'), use_container_width=True)

    # Categ√≥ricas
    st.subheader("üì¶ Vari√°veis Categ√≥ricas vs Churn")
    col4, col5, col6, col7 = st.columns(4)

    with col4:
        st.plotly_chart(px.histogram(df, x='NumOfProducts', color='Churn', barmode='group',
                                     title='N√∫mero de Produtos vs Churn'), use_container_width=True)

    with col5:
        st.plotly_chart(px.histogram(df, x='IsActiveMember', color='Churn', barmode='group',
                                     title='Cliente Ativo vs Churn',
                                     labels={'IsActiveMember': 'Ativo (1=Sim, 0=N√£o)'}), use_container_width=True)

    with col6:
        st.plotly_chart(px.histogram(df, x='Geography', color='Churn', barmode='group',
                                     title='Geografia vs Churn'), use_container_width=True)

    with col7:
        st.plotly_chart(px.histogram(df, x='Gender', color='Churn', barmode='group',
                                     title='G√™nero vs Churn'), use_container_width=True)

    st.markdown("---")
    st.caption("Desenvolvido por Silvia Laryssa ‚Äì Streamlit + Plotly üìä")
    
    
    
def treinar_modelo_logistico(df):
    # Sele√ß√£o das vari√°veis
    X = df[['Age', 'Balance', 'IsActiveMember', 'NumOfProducts', 'Geography']]
    y = df['Churn']

    # Treinamento e teste
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Pipeline
    preprocessor = ColumnTransformer(
        transformers=[('geo', OneHotEncoder(drop='first'), ['Geography'])],
        remainder='passthrough'
    )

    pipeline = Pipeline([
        ('prep', preprocessor),
        ('logreg', LogisticRegression(max_iter=1000))
    ])

    # Treinamento
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    # Avalia√ß√£o no Streamlit
    st.subheader("üìã Avalia√ß√£o do Modelo")
    cm = confusion_matrix(y_test, y_pred)
    st.write("**Matriz de Confus√£o:**")
    st.dataframe(pd.DataFrame(cm, columns=["Previsto 0", "Previsto 1"], index=["Real 0", "Real 1"]))

    st.markdown("**Relat√≥rio de Classifica√ß√£o:**")
    report = classification_report(y_test, y_pred, output_dict=True)
    st.dataframe(pd.DataFrame(report).transpose().round(2))

    # Coeficientes e interpreta√ß√£o
    st.subheader("üìà Coeficientes do Modelo")
    feature_names = pipeline.named_steps['prep'].get_feature_names_out()
    coef = pipeline.named_steps['logreg'].coef_[0]
    odds = np.exp(coef)

    coef_table = pd.DataFrame({
        'Vari√°vel': feature_names,
        'Coeficiente': coef.round(3),
        'Odds Ratio': odds.round(3)
    }).sort_values(by='Coeficiente', ascending=False)

    st.dataframe(coef_table)

    return X_test, y_test, pipeline   

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
import streamlit as st

def reajustar_modelo_logistico(X, y):
    """
    Ajusta um novo modelo de regress√£o log√≠stica com dados j√° codificados (X e y).

    Retorna:
    - pipeline treinado
    - y_pred (predi√ß√µes)
    - coef_table (tabela com coeficientes e odds)
    """

    # Pipeline apenas com scaler + regress√£o
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('logreg', LogisticRegression(max_iter=1000))
    ])

    # Treina o modelo
    pipeline.fit(X, y)
    y_pred = pipeline.predict(X)

    # Avalia√ß√£o do modelo
    st.subheader("üìã Avalia√ß√£o do Modelo Ajustado com Dados Transformados")
    st.write("**Matriz de Confus√£o:**")
    cm = confusion_matrix(y, y_pred)
    st.dataframe(pd.DataFrame(cm, columns=["Previsto 0", "Previsto 1"], index=["Real 0", "Real 1"]))

    st.markdown("**Relat√≥rio de Classifica√ß√£o:**")
    report = classification_report(y, y_pred, output_dict=True)
    st.dataframe(pd.DataFrame(report).transpose().round(2))

    # Coeficientes
    coef = pipeline.named_steps['logreg'].coef_[0]
    odds = np.exp(coef)
    feature_names = X.columns if hasattr(X, 'columns') else [f"X{i}" for i in range(len(coef))]

    coef_table = pd.DataFrame({
        'Vari√°vel': feature_names,
        'Coeficiente': coef.round(3),
        'Odds Ratio': odds.round(3)
    }).sort_values(by='Coeficiente', ascending=False)

    st.subheader("üìà Coeficientes do Modelo")
    st.dataframe(coef_table)

    return pipeline, y_pred, coef_table
 
 
# #############################################
from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, confusion_matrix
import plotly.graph_objects as go

def avaliar_modelo_classificacao(y_true, y_pred, y_prob):
    st.subheader("D) üìä Avalia√ß√£o Preditiva do Modelo")

    # M√©tricas principais
    acuracia = accuracy_score(y_true, y_pred)
    precisao = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    auc = roc_auc_score(y_true, y_prob)

    # Especificidade
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()
    especificidade = tn / (tn + fp)

    # Exibi√ß√£o das m√©tricas
    st.markdown("### üî¢ M√©tricas de Desempenho")
    st.write(f"**üéØ Acur√°cia:** {acuracia:.2f}")
    st.write(f"**üìå Precis√£o:** {precisao:.2f}")
    st.write(f"**üìà Sensibilidade (Recall):** {recall:.2f}")
    st.write(f"**üõ°Ô∏è Especificidade:** {especificidade:.2f}")
    st.write(f"**üìâ AUC (√Årea sob a Curva ROC):** {auc:.2f}")

    # Curva ROC
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    fig_roc = go.Figure()
    fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='Curva ROC', line=dict(color='blue')))
    fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Aleat√≥rio', line=dict(color='gray', dash='dash')))
    fig_roc.update_layout(
        title='Curva ROC',
        xaxis_title='Taxa de Falsos Positivos (1 - Especificidade)',
        yaxis_title='Taxa de Verdadeiros Positivos (Sensibilidade)',
        width=700,
        height=500
    )
    st.plotly_chart(fig_roc, use_container_width=True)


############################################## 

# ------------------------------
# MODELAGEM COM REGRESS√ÉO LOG√çSTICA
# ------------------------------
if show_model:
    st.header("üß† Quest√£o A e C - Modelagem com Regress√£o Log√≠stica (Reten√ß√£o de Clientes)")

    st.markdown("Selecionando vari√°veis explicativas mais relevantes:")
    st.code("Age, Balance, IsActiveMember, NumOfProducts, Geography")

    X_test, y_test, pipeline = treinar_modelo_logistico(df)


    # ------------------------------
    # VALIDA√á√ÉO DOS PRESSUPOSTOS DA REGRESS√ÉO LOG√çSTICA
    # ------------------------------
    st.header("B) üìè Valida√ß√£o dos Pressupostos da Regress√£o Log√≠stica")

    val_result = validar_pressupostos_logistica(X_test, y_test, pipeline)
    diagnostico_agrupamentos(pipeline, X_test, y_test)

    # 1. Balanceamento
    st.subheader("üìä Balanceamento da vari√°vel Churn")
    st.write(val_result['balanceamento'])
    if min(val_result['balanceamento'].values()) < 0.3:
        st.warning("üî¥ Churn desbalanceado ‚Äì considere aplicar SMOTE ou t√©cnicas de balanceamento.")

    # 2. Multicolinearidade
    st.subheader("üìå VIF ‚Äì Multicolinearidade")
    st.dataframe(val_result['vif_table'])
    if val_result['vif_table']['VIF'].max() > 5:
        st.warning("‚ö†Ô∏è VIF elevado detectado ‚Äì considere aplicar regulariza√ß√£o L1 ou L2.")

    # 3. Linearidade do logit
    st.subheader("üìà Linearidade entre preditores e logit")
    st.altair_chart(val_result['fig_linearidade'], use_container_width=True) 

    # 4. Recomenda√ß√µes autom√°ticas
    st.subheader("üß™ Diagn√≥stico Final")
    if val_result['aplicar_smote']:
        st.markdown("‚úÖ **Sugest√£o:** Aplicar SMOTE para balancear as classes.")

    if val_result['recomendar_regularizacao']:
        st.markdown("‚úÖ **Sugest√£o:** Aplicar regulariza√ß√£o **L1 (Lasso)** ou **L2 (Ridge)** para mitigar multicolinearidade.")

    aplicar_smote_usuario = st.checkbox("Deseja aplicar SMOTE para balancear as classes?")
    if aplicar_smote_usuario:
        if min(val_result['balanceamento'].values()) < 0.3:
            st.info("üîÑ Aplicando SMOTE ap√≥s codifica√ß√£o dos dados...")

            # Transforma X_test com o mesmo pr√©-processador do pipeline
            X_test_encoded = pipeline.named_steps['prep'].transform(X_test)
            feature_names = pipeline.named_steps['prep'].get_feature_names_out()
            X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=feature_names)

            # Aplica SMOTE com os dados num√©ricos
            smote = SMOTE(random_state=42)
            X_resampled, y_resampled = smote.fit_resample(X_test_encoded_df, y_test)

            st.success("‚úÖ SMOTE aplicado com sucesso!")
            st.write("Distribui√ß√£o ap√≥s SMOTE:")
            st.dataframe(y_resampled.value_counts(normalize=True))

            # Atualize os valores usados no restante do app, se necess√°rio
            st.markdown("üîÑ Atualizando modelo com dados balanceados...")
            # Reajusta o modelo com os dados balanceados
            pipeline, y_pred, coef_table = reajustar_modelo_logistico(X_resampled, y_resampled)
            
            st.subheader("üìà Coeficientes do Modelo Ajustado com SMOTE")
            data_interpretativa = {
                "Vari√°vel": [
                    "geo__Geography_Germany",
                    "geo__Geography_Spain",
                    "remainder__Age",
                    "remainder__Balance",
                    "remainder__NumOfProducts",
                    "remainder__IsActiveMember"
                ],
                "Coeficiente": [
                    "+0.384",
                    "‚Äì0.096",
                    "+0.925",
                    "+0.165",
                    "‚Äì0.132",
                    "‚Äì0.552"
                ],
                "Odds Ratio": [
                    "1.468",
                    "0.908",
                    "2.523",
                    "1.179",
                    "0.877",
                    "0.576"
                ],
                "Impacto sobre o Churn (%)": [
                    "+46,8%",
                    "‚Äì9,2%",
                    "+152,3% por ano",
                    "+17,9%",
                    "‚Äì12,3% por produto",
                    "‚Äì42,4%"
                ],
                "Interpreta√ß√£o Detalhada": [
                    "Clientes da Alemanha t√™m 1,46x mais chance de churn do que clientes da Fran√ßa. Forte associa√ß√£o com sa√≠da.",
                    "Clientes da Espanha t√™m 9,2% menos chance de churn comparado √† Fran√ßa. Leve prote√ß√£o contra sa√≠da.",
                    "A cada ano a mais de idade, a chance de churn aumenta em 152,3%, sugerindo forte sa√≠da entre clientes mais velhos.",
                    "Saldo positivo tem impacto leve no aumento da chance de churn.",
                    "Cada produto banc√°rio adicional reduz a chance de churn em 12,3%. Clientes com mais produtos s√£o mais fi√©is.",
                    "Clientes ativos t√™m 42,4% menos chance de churn. Fator importante de reten√ß√£o no modelo."
                ]
            }
        df_interpretativa = pd.DataFrame(data_interpretativa)
        st.table(df_interpretativa)
        st.markdown("### üß© Conclus√µes Estrat√©gicas da An√°lise de Churn ")
        st.markdown("""
        - **Clientes ativos** t√™m menor probabilidade de churn. Invista em a√ß√µes para ativar clientes inativos.
        - **N√∫mero de produtos banc√°rios** est√° negativamente relacionado ao churn. Estrat√©gias de cross-selling podem ser eficazes.
        - **Clientes da Alemanha** apresentam maior risco e devem ser analisados regionalmente.
        - **Idade** √© o fator mais cr√≠tico: quanto mais velho o cliente, maior a chance de churn. Personalize ofertas para esse p√∫blico.
        - **Saldo banc√°rio** mostrou influ√™ncia leve, sugerindo que reten√ß√£o depende mais do engajamento do que do volume financeiro.
        - **A geografia** tem impacto consider√°vel. A Espanha demonstra maior fidelidade.
        """)

        # Avalia√ß√£o do desempenho com dados balanceados (SMOTE)
        y_prob = pipeline.predict_proba(X_resampled)[:, 1]
        avaliar_modelo_classificacao(y_true=y_resampled, y_pred=y_pred, y_prob=y_prob)
        st.markdown("""
        ### üìä Interpreta√ß√£o das M√©tricas de Desempenho

        - **Acur√°cia (0.72):** 72% das previs√µes totais foram corretas.  
        - **Precis√£o (0.72):** 72% dos clientes previstos como churn realmente sa√≠ram.  
        - **Sensibilidade/Recall (0.73):** O modelo identificou corretamente 73% dos clientes que sa√≠ram.  
        - **Especificidade (0.72):** Acertou 72% dos clientes que permaneceram.  
        - **AUC (0.78):** Boa capacidade geral de distinguir entre quem sai e quem fica.

        ‚úÖ O modelo apresenta **desempenho equilibrado** e √© adequado para **a√ß√µes estrat√©gicas de reten√ß√£o**.
        """)  

        
    else:
                # Exemplo: salvar em sess√£o, ou atualizar os gr√°ficos/predi√ß√µes
        #st.warning("‚ö†Ô∏è As classes j√° est√£o relativamente balanceadas. SMOTE n√£o √© necess√°rio.")

            
    
        # dataframe com a interpreta√ß√£o dos coeficientes
        st.header("üìä Tabela Interpretativa dos Coeficientes antes do SMOTE")

        # Dados da tabela interpretativa
        data_interpretativa1 = {
            "Vari√°vel": [
                "geo__Geography_Germany",
                "geo__Geography_Spain",
                "remainder__Age",
                "remainder__Balance",
                "remainder__NumOfProducts",
                "remainder__IsActiveMember"
            ],
            "Coeficiente": [
                "+0.798",
                "+0.084",
                "+0.072",
                "0",
                "‚Äì0.075",
                "‚Äì1.059"
            ],
            "Odds Ratio": [
                "2.222",
                "1.088",
                "1.075",
                "1.000",
                "0.928",
                "0.347"
            ],
            "Impacto sobre o Churn (%)": [
                "+122,2%",
                "+8,8%",
                "+7,5% por ano",
                "0%",
                "‚Äì7,2% por produto",
                "‚Äì65,3%"
            ],
            "Interpreta√ß√£o Detalhada": [
                "Clientes da Alemanha t√™m 2,2x mais chance de churn do que clientes da Fran√ßa (grupo base). Forte associa√ß√£o com sa√≠da.",
                "Clientes da Espanha t√™m 8,8% mais chance de churn comparado √† Fran√ßa. Efeito pequeno, quase neutro.",
                "A cada ano a mais de idade, a chance de churn aumenta em 7,5%, sugerindo maior sa√≠da entre clientes mais velhos.",
                "O saldo na conta n√£o teve efeito significativo sobre o churn neste modelo.",
                "Cada produto banc√°rio adicional reduz a chance de churn em 7,2%. Clientes com mais produtos s√£o mais fi√©is.",
                "Clientes ativos t√™m 65,3% menos chance de churn. √â o fator mais forte de reten√ß√£o no modelo."
            ]
        }

    
        df_interpretativa1 = pd.DataFrame(data_interpretativa1)

        # Exibir a tabela no Streamlit
        st.table(df_interpretativa1)

     

    st.markdown("---")
    st.caption("üîç Coeficientes positivos aumentam a chance de churn; negativos indicam maior reten√ß√£o.")
    st.markdown("> **Interpreta√ß√£o:** Coeficientes positivos aumentam a chance de churn; negativos diminuem. A coluna `Odds Ratio` mostra quanto a chance √© multiplicada para cada unidade da vari√°vel.")
    
    st.markdown("""
        ---

        ### üìö Refer√™ncias
        - Field, A. (2009). *Descobrindo a estat√≠stica usando o SPSS*. 2. ed. Porto Alegre: Artmed, 2009
        - Grus, J. (2021). Data science do zero: no√ß√µes fundamentais com Python (2¬™ ed.). Alta Books.

        ---

        ### Autores
        - **PPCA**: Programa de Computa√ß√£o Aplicada - UNB  
        - **AEDI**: An√°lise Estat√≠stica de Dados e Informa√ß√µes  
        - **Prof.** Jo√£o Gabriel de Moraes Souza  
        - **Aluna**: Silva Laryssa Branco da Silva  
        - **Data**: 2025/07/18

        ### üîó Links

        - Projeto no HungginFace: [https://huggingface.co/spaces/silviabranco/regressaologistica](https://huggingface.co/spaces/silviabranco/regressaologistica)  
        - Projeto Community Cloud: [https://regressaologisticaaeidunb.streamlit.app/](https://regressaologisticaaeidunb.streamlit.app/)    
        - GITHub: [https://github.com/silvialaryssa/regressaologistica.git](https://github.com/silvialaryssa/regressaologistica)
      
        """)
